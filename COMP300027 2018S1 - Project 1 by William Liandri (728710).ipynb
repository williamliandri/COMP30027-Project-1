{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2018 Semester 1\n",
    "-----\n",
    "## Project 1: What is labelled data worth to Naive Bayes?\n",
    "-----\n",
    "###### Student Name(s): William Liandri\n",
    "###### Student ID: 728710\n",
    "###### Python version: 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you may use for your Project 1 submission. (You are not required to use it; in particular, there is no need to use iPython if you do not like it.)\n",
    "\n",
    "Marking will be applied on the seven functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def preprocess(filedir):\n",
    "    df = pd.read_csv(filedir, header=None)\n",
    "    \n",
    "    # Remove the missing values from the data\n",
    "    df = remove_missing_values(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will help to remove instance that have missing values.\n",
    "def remove_missing_values(df):\n",
    "    newdf = pd.DataFrame\n",
    "    list_data = []\n",
    "    df_columns = df.columns\n",
    "    tempDict = OrderedDict()\n",
    "    totalMissingValues = 0\n",
    "    \n",
    "    # Iterate through the data to find missing values. \n",
    "    for i in df.values:\n",
    "\n",
    "        # The instance does not contain missing values, so append it to the tempList.\n",
    "        if('?' not in i):\n",
    "            list_data.append(i)\n",
    "        \n",
    "        # Record the number of missing values\n",
    "        else:\n",
    "            totalMissingValues += 1\n",
    "            \n",
    "    # Put the data back into DataFrame. \n",
    "    for i in range(len(df_columns)):\n",
    "        tempData = [k[i] for k in list_data]\n",
    "        tempDict[df_columns[i]] = tempData\n",
    "    \n",
    "    return newdf.from_dict(tempDict), totalMissingValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model.\n",
    "def train_supervised(df):   \n",
    "    \n",
    "    # Calculate the priors and the posteriors\n",
    "    prob_priors = prob_priors_supervised(df)\n",
    "    posteriors = count_posteriors_supervised(df)\n",
    "    \n",
    "    prob_posteriors = prob_posteriors_supervised(df, posteriors)\n",
    "    \n",
    "    return prob_priors, prob_posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will calculate the probability priors of the data.\n",
    "def prob_priors_supervised(df):\n",
    "    \n",
    "    last_column = df.columns[len(df.columns) - 1]\n",
    "    tempDict = pd.value_counts(df[last_column]).to_dict()\n",
    "    sumPriors = sum(tempDict.values())\n",
    "\n",
    "    # Calculate the probability of the priors\n",
    "    for i in tempDict.keys():\n",
    "        tempDict[i] /= sumPriors\n",
    "    \n",
    "    return tempDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will count the posteriors of the data.\n",
    "def count_posteriors_supervised(df):\n",
    "    \n",
    "    columns = df.columns\n",
    "    df_posteriors = defaultdict(defaultdict)\n",
    "    \n",
    "    # Iterate through the columns\n",
    "    for i in range(len(columns) - 1):\n",
    "        dictdf = defaultdict(defaultdict)\n",
    "        \n",
    "        # Find the unique values for the labelled class\n",
    "        unique_class = df[columns[len(columns) - 1]].unique()\n",
    "        \n",
    "        # Iterate through the unique values.\n",
    "        for j in range(len(unique_class)):\n",
    "            dictdf2 = defaultdict(int)\n",
    "            \n",
    "            #Iterate through the data\n",
    "            for k in range(len(df.values)):\n",
    "                \n",
    "                # Calcuate the posteriors probability.\n",
    "                if(df.values[k][len(columns)-1] == unique_class[j]):\n",
    "                    dictdf2[df.values[k][i]] += 1\n",
    "                \n",
    "            # Put the data into the dictionaries and array.\n",
    "            dictdf[unique_class[j]] = dictdf2\n",
    "                    \n",
    "        df_posteriors[columns[i]] = dictdf\n",
    "        \n",
    "    return df_posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function will calculate the probability of the posteriors of the data.\n",
    "def prob_posteriors_supervised(df, dictPosteriors):\n",
    "    \n",
    "    columns = df.columns\n",
    "    \n",
    "    # The classes\n",
    "    uniqueClass = df[columns[-1]].unique()\n",
    "    \n",
    "    # How many times the specified class appear in the data. \n",
    "    countUniqueClass = pd.value_counts(df[columns[-1]]).to_dict()\n",
    "    \n",
    "    # Iterate through the attributes\n",
    "    for i in range(len(columns) - 1):\n",
    "        uniqueAttributes = df[columns[i]].unique()\n",
    "    \n",
    "        for currClass in uniqueClass:\n",
    "            for currAttrb in uniqueAttributes:\n",
    "                \n",
    "                # Calculating the probability of the posteriors and also do the\n",
    "                # smoothing (Laplace smoothing).\n",
    "                dictPosteriors[columns[i]][currClass][currAttrb] += 1\n",
    "                divisor = (len(uniqueAttributes) + countUniqueClass[currClass])\n",
    "                dictPosteriors[columns[i]][currClass][currAttrb] /= divisor\n",
    "                \n",
    "    return dictPosteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should predict the class for a set of instances, based on a trained model. \n",
    "def predict_supervised(df, priors_df, posteriors_df):\n",
    "    \n",
    "    predictionResults = []\n",
    "    listdf = df.values\n",
    "    columns = df.columns\n",
    "    uniqueClass = priors_df.keys()\n",
    "    \n",
    "    # Iterate through the data and make a prediction using Naive Bayes. \n",
    "    for i in range(len(listdf)):\n",
    "        calcPredictions = []\n",
    "        \n",
    "        for j in uniqueClass:\n",
    "                \n",
    "            # Multiply the probability with the priors. \n",
    "            currProb = math.log(priors_df[j])\n",
    "            \n",
    "            for k in range(len(listdf[i]) - 1):\n",
    "                currProb += math.log(posteriors_df[columns[k]][j][listdf[i][k]])\n",
    "                \n",
    "            # Record all of the calculation.\n",
    "            calcPredictions.append([currProb,j])\n",
    "            \n",
    "        # Find the one that has the maximum value and store the predicted class.\n",
    "        predictionResults.append(max(calcPredictions)[1])\n",
    "    \n",
    "    return predictionResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context. \n",
    "def evaluate_supervised(df, predict_df):\n",
    "    \n",
    "    totalCorrect = 0\n",
    "    \n",
    "    # Iterate through the data and find how many correct predictions.\n",
    "    for i in range(len(df.values)):\n",
    "        last_element = len(df.values[i]) - 1\n",
    "        if(predict_df[i] == df.values[i][last_element]):\n",
    "            \n",
    "            totalCorrect += 1\n",
    "            \n",
    "    return totalCorrect/len(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_unsupervised(df):\n",
    "    \n",
    "    # Insert some random numbers according to the number of classes.\n",
    "    listFractionClasses = generate_random_value(df)\n",
    "    \n",
    "    # Calculate the priors and the posteriors probabilities.\n",
    "    prob_priors = prob_priors_unsupervised(df, listFractionClasses)\n",
    "    prob_posteriors = prob_posteriors_unsupervised(df, listFractionClasses)\n",
    "    \n",
    "    return prob_priors, prob_posteriors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This functions will generate random fractional value for each class.\n",
    "def generate_random_value(df):\n",
    "    \n",
    "    # Get the unique classes that the data has.\n",
    "    uniqueClasses = df[df.columns[-1]].unique()\n",
    "    \n",
    "    listFractionValue = []\n",
    "    \n",
    "    # Generate random fractional value.\n",
    "    for i in range(len(df)):\n",
    "        randNum = np.random.dirichlet(np.ones(len(uniqueClasses)))\n",
    "        dictFractionValue = defaultdict(float)\n",
    "        \n",
    "        # Maps the random value to the class and stores it in a dictionary.\n",
    "        for j in range(len(uniqueClasses)):\n",
    "            dictFractionValue[uniqueClasses[j]] = randNum[j] \n",
    "        listFractionValue.append(dictFractionValue)\n",
    "        \n",
    "    return listFractionValue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_priors_unsupervised(df, listFractionClasses):\n",
    "    \n",
    "    columns = df.columns\n",
    "\n",
    "    # Find the possible classes in the given dataset.\n",
    "    uniqueClasses = df[df.columns[-1]].unique()\n",
    "    \n",
    "    # Dictionary to store the priors probability. \n",
    "    dictPriors = defaultdict(float)\n",
    "\n",
    "    for i in range(len(uniqueClasses)):\n",
    "        currPriors = [k[uniqueClasses[i]] for k in listFractionClasses]\n",
    "\n",
    "        dictPriors[uniqueClasses[i]] = sum(currPriors)/len(df)\n",
    "        \n",
    "    return dictPriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_posteriors_unsupervised(df, listFractionClasses):\n",
    "    \n",
    "    columns = df.columns\n",
    "    \n",
    "    # Find the possible classes in the given dataset. \n",
    "    uniqueClasses = df[df.columns[-1]].unique()\n",
    "    \n",
    "    # Dictionary to store the posteriors probability.\n",
    "    dictPosteriors = defaultdict(lambda: defaultdict(lambda: defaultdict(float)))\n",
    "    \n",
    "    # Convert the data into list\n",
    "    listData = df.values\n",
    "    \n",
    "    # Iterate through the instances.\n",
    "    for i in range(len(listData)):\n",
    "        \n",
    "        # Iterate through each of the attributes\n",
    "        for j in range(len(listData[i])):\n",
    "            \n",
    "            # Iterate through the classes\n",
    "            for k in range(len(uniqueClasses)):\n",
    "                dictPosteriors[j][uniqueClasses[k]][listData[i][j]] += listFractionClasses[i][uniqueClasses[k]]\n",
    "    \n",
    "    # Divided by class counts to get the probabilities.    \n",
    "    for i in dictPosteriors.keys():\n",
    "        \n",
    "        for j in dictPosteriors[i].keys():\n",
    "            totalClassCounts = sum(dictPosteriors[i][j].values())\n",
    "            \n",
    "            for k in dictPosteriors[i][j].keys():\n",
    "                initialValue = dictPosteriors[i][j][k]\n",
    "                dictPosteriors[i][j][k] = initialValue/totalClassCounts\n",
    "    \n",
    "    return dictPosteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_unsupervised(df, priors_df, posteriors_df):\n",
    "    \n",
    "    # Convert the data into a list. \n",
    "    listData = df.values\n",
    "        \n",
    "    columns = df.columns\n",
    "    \n",
    "    # The possible classes on the dataset\n",
    "    uniqueClasses = df[columns[-1]].unique()\n",
    "    \n",
    "    # Specify a random number of iterations.\n",
    "    noIterations = random.randint(10,15)\n",
    "    \n",
    "    for iteration in range(0, noIterations):\n",
    "    \n",
    "        # An array to store the results of the prediction \n",
    "        predictionResults = []\n",
    "    \n",
    "        # An array to store fraction value for the next iteration.\n",
    "        newFractionValue = []\n",
    "\n",
    "        for i in range(len(listData)):\n",
    "            calcPredictions = []\n",
    "            classPredictions = []\n",
    "            for j in uniqueClasses:\n",
    "                currProb = priors_df[j]\n",
    "                \n",
    "                for k in range(len(listData[i]) - 1):\n",
    "                    currProb *= posteriors_df[k][j][listData[i][k]]\n",
    "        \n",
    "                # Record the results\n",
    "                calcPredictions.append(currProb)\n",
    "                classPredictions.append(j)\n",
    "        \n",
    "            # Normalize the data\n",
    "            totalPredictions = sum(calcPredictions)\n",
    "            calcPredictions = [value/totalPredictions for value in calcPredictions]\n",
    "    \n",
    "            # Store the value to newFractionValue to be used for the next iteration.\n",
    "            tempDictFractionValue = {}\n",
    "            for noClasses in range(len(classPredictions)):\n",
    "                tempDictFractionValue[classPredictions[noClasses]] = calcPredictions[noClasses]\n",
    "            newFractionValue.append(tempDictFractionValue)\n",
    "    \n",
    "            # Record the predicted class.\n",
    "            predictionResults.append(classPredictions[calcPredictions.index(max(calcPredictions))])\n",
    "    \n",
    "        priors_df = prob_priors_unsupervised(df, newFractionValue)\n",
    "        posteriors_df = prob_posteriors_unsupervised(df, newFractionValue)\n",
    "    \n",
    "    return predictionResults, noIterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context. \n",
    "def evaluate_unsupervised(df, predict_df):\n",
    "    \n",
    "    totalCorrect = 0\n",
    "    \n",
    "    # Iterate through the data and find how many correct predictions.\n",
    "    for i in range(len(df.values)):\n",
    "        \n",
    "        # Get the index of the actual class in the original dataset. \n",
    "        indActualClass = len(df.values[i]) - 1\n",
    "        if(predict_df[i] == df.values[i][indActualClass]):\n",
    "            totalCorrect += 1\n",
    "            \n",
    "    return totalCorrect/len(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## breast_cancer.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 9 missing values.\n",
      "The accuracy for supervised Naive Bayes is 0.7689530685920578\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "df1, df1_missing_values = preprocess('2018S1-proj1_data/breast-cancer.csv')\n",
    "\n",
    "# SUPERVISED\n",
    "supervised_priors_df1, supervised_posteriors_df1 = train_supervised(df1)\n",
    "predict_supervised_df1 = predict_supervised(df1, supervised_priors_df1, supervised_posteriors_df1)\n",
    "evaluate_supervised_df1 = evaluate_supervised(df1, predict_supervised_df1)\n",
    "\n",
    "print(\"This dataset has {} missing values.\".format(df1_missing_values))\n",
    "print(\"The accuracy for supervised Naive Bayes is \" + str(evaluate_supervised_df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of iterations is 13. The accuracy for unsupervised Naive Bayes is 0.7328519855595668\n"
     ]
    }
   ],
   "source": [
    "# UNSUPERVISED\n",
    "unsupervised_priors_df1, unsupervised_posteriors_df1 = train_unsupervised(df1)\n",
    "predict_unsupervised_df1, noIterations = predict_unsupervised(df1, unsupervised_priors_df1, unsupervised_posteriors_df1)\n",
    "evaluate_unsupervised_df1 = evaluate_unsupervised(df1, predict_unsupervised_df1)\n",
    "\n",
    "print(\"The total number of iterations is \" + str(noIterations) + \". \"\n",
    "      \"The accuracy for unsupervised Naive Bayes is \" + str(evaluate_unsupervised_df1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## car.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 0 missing values.\n",
      "The accuracy for supervised Naive Bayes is 0.8715277777777778\n"
     ]
    }
   ],
   "source": [
    "df2, df2_missing_values = preprocess('2018S1-proj1_data/car.csv')\n",
    "\n",
    "# SUPERVISED\n",
    "supervised_priors_df2, supervised_posteriors_df2 = train_supervised(df2)\n",
    "predict_supervised_df2 = predict_supervised(df2, supervised_priors_df2, supervised_posteriors_df2)\n",
    "evaluate_supervised_df2 = evaluate_supervised(df2, predict_supervised_df2)\n",
    "\n",
    "print(\"This dataset has {} missing values.\".format(df2_missing_values))\n",
    "print(\"The accuracy for supervised Naive Bayes is \" + str(evaluate_supervised_df2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of iterations is 12. The accuracy for unsupervised Naive Bayes is 0.42476851851851855\n"
     ]
    }
   ],
   "source": [
    "# UNSUPERVISED\n",
    "unsupervised_priors_df2, unsupervised_posteriors_df2 = train_unsupervised(df2)\n",
    "predict_unsupervised_df2, noIterations = predict_unsupervised(df2, unsupervised_priors_df2, unsupervised_posteriors_df2)\n",
    "evaluate_unsupervised_df2 = evaluate_unsupervised(df2, predict_unsupervised_df2)\n",
    "\n",
    "print(\"The total number of iterations is \" + str(noIterations) + \". \"\n",
    "      \"The accuracy for unsupervised Naive Bayes is \" + str(evaluate_unsupervised_df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypothyroid.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 73 missing values.\n",
      "The accuracy for supervised Naive Bayes is 0.9514563106796117\n"
     ]
    }
   ],
   "source": [
    "df3, df3_missing_values = preprocess('2018S1-proj1_data/hypothyroid.csv')\n",
    "\n",
    "# SUPERVISED\n",
    "supervised_priors_df3, supervised_posteriors_df3 = train_supervised(df3)\n",
    "predict_supervised_df3 = predict_supervised(df3, supervised_priors_df3, supervised_posteriors_df3)\n",
    "evaluate_supervised_df3 = evaluate_supervised(df3, predict_supervised_df3)\n",
    "\n",
    "print(\"This dataset has {} missing values.\".format(df3_missing_values))\n",
    "print(\"The accuracy for supervised Naive Bayes is \" + str(evaluate_supervised_df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of iterations is 15. The accuracy for unsupervised Naive Bayes is 0.8728155339805825\n"
     ]
    }
   ],
   "source": [
    "# UNSUPERVISED\n",
    "unsupervised_priors_df3, unsupervised_posteriors_df3 = train_unsupervised(df3)\n",
    "predict_unsupervised_df3, noIterations = predict_unsupervised(df3, unsupervised_priors_df3, unsupervised_posteriors_df3)\n",
    "evaluate_unsupervised_df3 = evaluate_unsupervised(df3, predict_unsupervised_df3)\n",
    "\n",
    "print(\"The total number of iterations is \" + str(noIterations) + \". \"\n",
    "      \"The accuracy for unsupervised Naive Bayes is \" + str(evaluate_unsupervised_df3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mushroom.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 2480 missing values.\n",
      "The accuracy for supervised Naive Bayes is 0.976966690290574\n"
     ]
    }
   ],
   "source": [
    "df4, df4_missing_values = preprocess('2018S1-proj1_data/mushroom.csv')\n",
    "\n",
    "# SUPERVISED\n",
    "supervised_priors_df4, supervised_posteriors_df4 = train_supervised(df4)\n",
    "predict_supervised_df4 = predict_supervised(df4, supervised_priors_df4, supervised_posteriors_df4)\n",
    "evaluate_supervised_df4 = evaluate_supervised(df4, predict_supervised_df4)\n",
    "\n",
    "print(\"This dataset has {} missing values.\".format(df4_missing_values))\n",
    "print(\"The accuracy for supervised Naive Bayes is \" + str(evaluate_supervised_df4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of iterations is 14. The accuracy for unsupervised Naive Bayes is 0.8525868178596739\n"
     ]
    }
   ],
   "source": [
    "# UNSUPERVISED\n",
    "unsupervised_priors_df4, unsupervised_posteriors_df4 = train_unsupervised(df4)\n",
    "predict_unsupervised_df4, noIterations = predict_unsupervised(df4, unsupervised_priors_df4, unsupervised_posteriors_df4)\n",
    "evaluate_unsupervised_df4 = evaluate_unsupervised(df4, predict_unsupervised_df4)\n",
    "\n",
    "print(\"The total number of iterations is \" + str(noIterations) + \". \"\n",
    "      \"The accuracy for unsupervised Naive Bayes is \" + str(evaluate_unsupervised_df4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. Since we’re starting off with random guesses, it might be surprising that the unsupervised NB works at all. Explain what characteristics of the data cause it to work pretty well (say, within 10% Accuracy of the supervised NB) most of the time; also, explain why it utterly fails sometimes.\n",
    "2. When evaluating supervised NB across the four different datasets, you will observe some variation in effectiveness (e.g. Accuracy). Explain what causes this variation. Describe and explain any particularly suprising results.\n",
    "3. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out (hint: check out numpy.shuffle()) or cross–validation evaluation strategy. How does your estimate of Accuracy change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "4. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Do you notice any variation in the predictions made by either the supervised or unsupervised NB classifiers? Explain why, or why not.\n",
    "5. The lecture suggests that deterministically labelling the instances in the initialisation phase of the unsupervised NB classifier “doesn’t work very well”. Confirm this for yourself, and then demonstrate why.\n",
    "6. Rather than evaluating the unsupervised NB classifier by assigning a class deterministically, instead calculate how far away the probabilistic estimate of the true class is from 1 (where we would be certain of the correct class), and take the average over the instances. Does this performance estimate change, as we alter the number of iterations in the method? Explain why.\n",
    "7. Explore what causes the unsupervised NB classifier to converge: what proportion of instances change their prediction from the random assignment, to the first iteration? From the first to the second? What is the latest iteration where you observe a prediction change? Make some conjecture(s) as to what is occurring here.\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question. Groups of 2 students should respond to question (1), and three other questions. Your responses should be about 100-200 words each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breast Cancer\n",
    "The accuracy for supervised Naive Bayes is 0.7689530685920578\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
